{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annvorosh/GB/blob/ML_Med/%D1%83%D0%B4%D0%B0%D0%BB%D0%B8%D1%82%D1%8C_%22UNET_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30931979",
      "metadata": {
        "id": "30931979"
      },
      "source": [
        "# Введение в нейронные сети\n",
        "\n",
        "## Урок 6. Сегментация\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "94b8823d",
      "metadata": {
        "id": "94b8823d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, BatchNormalization, Concatenate, Conv2DTranspose, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ncQf4tTvFK6O"
      },
      "id": "ncQf4tTvFK6O",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "6d01c8a1",
      "metadata": {
        "id": "6d01c8a1"
      },
      "outputs": [],
      "source": [
        "# Константы\n",
        "IMG_WIDTH = 336                       # Ширина изображения\n",
        "IMG_HEIGHT = 336                      # Высота изображения\n",
        "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT)   # Формат изображения (ширина, высота)\n",
        "CLASSES = 2                           # Число классов сегментирования (полип и фон)\n",
        "IMG_CHANNELS = 3\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь к файлу архива\n",
        "zip_file_path = '/content/archive.zip'\n",
        "extracted_dir_path = '/content/kvasir_capsule_seg'\n",
        "\n",
        "# Распаковка архива\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir_path)"
      ],
      "metadata": {
        "id": "hrrX09McExL7"
      },
      "id": "hrrX09McExL7",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8bcac637",
      "metadata": {
        "id": "8bcac637"
      },
      "outputs": [],
      "source": [
        "# Путь к папкам с изображениями и масками\n",
        "extracted_dir_path = '/content/kvasir_capsule_seg'\n",
        "images_dir = os.path.join(extracted_dir_path, 'Kvasir-Capsule/images')\n",
        "masks_dir = os.path.join(extracted_dir_path, 'Kvasir-Capsule/masks')\n",
        "\n",
        "# Получение списка файлов\n",
        "image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.jpg')])\n",
        "mask_files = sorted([f for f in os.listdir(masks_dir) if f.endswith('.jpg')])\n",
        "\n",
        "# Создание датафрейма для удобства работы\n",
        "data_df = pd.DataFrame({\n",
        "    'image': [os.path.join(images_dir, f) for f in image_files],\n",
        "    'mask': [os.path.join(masks_dir, f) for f in mask_files]\n",
        "})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b5810563",
      "metadata": {
        "id": "b5810563"
      },
      "outputs": [],
      "source": [
        "# Разделение на обучающую и тестовую выборки\n",
        "train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "19608128",
      "metadata": {
        "id": "19608128"
      },
      "outputs": [],
      "source": [
        "# Загрузка данных\n",
        "def load_data(df):\n",
        "    images = []\n",
        "    masks = []\n",
        "    for _, row in df.iterrows():\n",
        "        image = Image.open(row['image']).convert('RGB')  # Преобразование изображения в RGB\n",
        "        mask = Image.open(row['mask']).convert('RGB')    # Преобразование маски в RGB\n",
        "        image = tf.convert_to_tensor(np.array(image))    # Преобразование изображения в тензор\n",
        "        mask = tf.convert_to_tensor(np.array(mask))      # Преобразование маски в тензор\n",
        "        image = tf.image.resize(image, IMG_SHAPE)        # Изменение размера изображения\n",
        "        mask = tf.image.resize(mask, IMG_SHAPE)          # Изменение размера маски\n",
        "        images.append(image)\n",
        "        masks.append(mask)\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "X_train, Y_train = load_data(train_df)\n",
        "X_test, Y_test = load_data(test_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf7d2c4",
      "metadata": {
        "id": "faf7d2c4"
      },
      "source": [
        "### Функции предобработки и пост обработки данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "abb7b9ad",
      "metadata": {
        "id": "abb7b9ad"
      },
      "outputs": [],
      "source": [
        "def convert_from_color(arr_3d, palette):\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
        "    for c, i in palette.items():\n",
        "        arr_2d[arr_3d[:, :, 0] == c[0]] = i\n",
        "    return arr_2d\n",
        "\n",
        "\n",
        "def preprocess_masks(masks, num_classes):\n",
        "    processed_masks = []\n",
        "    palette = {\n",
        "        (0, 0, 0): 0,        # Фон (чёрный)\n",
        "        (255, 255, 255): 1   # Полип (белый)\n",
        "    }\n",
        "    for mask in masks:\n",
        "        mask = mask[:, :, :3]  # Убираем альфа-канал, если он есть\n",
        "        mask = convert_from_color(mask, palette)  # Преобразование цвета в метки классов\n",
        "        mask = tf.keras.utils.to_categorical(mask, num_classes)\n",
        "        processed_masks.append(mask)\n",
        "    return np.array(processed_masks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "b1695cc1",
      "metadata": {
        "id": "b1695cc1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "46e35f0a",
      "metadata": {
        "id": "46e35f0a"
      },
      "outputs": [],
      "source": [
        "# Подготовка данных для нейронной сети\n",
        "X_train = X_train / 255.0  # Нормализация\n",
        "X_test = X_test / 255.0    # Нормализация\n",
        "Y_train = preprocess_masks(Y_train, CLASSES)\n",
        "Y_test = preprocess_masks(Y_test, CLASSES)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05e9bcc5",
      "metadata": {
        "id": "05e9bcc5"
      },
      "source": [
        "### Предобработка исходных изображений и сегментированных изображений в ответ сети"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "234b82c0",
      "metadata": {
        "id": "234b82c0"
      },
      "source": [
        "### Объявление топологии нейронной сети, компиляция и обучение"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, Dropout, Concatenate, LeakyReLU\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def unet_model(image_size=(336, 336), output_classes=1):\n",
        "    input_layer = Input(shape=image_size + (3,))\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 4, activation=LeakyReLU(), strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(input_layer)\n",
        "    conv1_1 = Conv2D(128, 4, activation=LeakyReLU(), strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(conv1)\n",
        "    conv2 = Conv2D(256, 4, activation=LeakyReLU(), strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(conv1_1)\n",
        "    conv3 = Conv2D(512, 4, activation=LeakyReLU(), strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(conv2)\n",
        "    conv4 = Conv2D(512, 4, activation=LeakyReLU(), strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(conv3)\n",
        "    conv5 = Conv2D(512, 4, activation=LeakyReLU(), strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(conv4)\n",
        "    conv6 = Conv2D(512, 4, activation=LeakyReLU(), strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up1 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(conv6), conv5])\n",
        "    up1 = BatchNormalization()(up1)\n",
        "    up1 = Dropout(0.25)(up1)\n",
        "\n",
        "    up2 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(up1), conv4])\n",
        "    up2 = BatchNormalization()(up2)\n",
        "    up2 = Dropout(0.25)(up2)\n",
        "\n",
        "    up3 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(up2), conv3])\n",
        "    up3 = BatchNormalization()(up3)\n",
        "    up3 = Dropout(0.25)(up3)\n",
        "\n",
        "    up4 = Concatenate()([Conv2DTranspose(256, 4, activation='relu', strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(up3), conv2])\n",
        "    up4 = BatchNormalization()(up4)\n",
        "\n",
        "    up5 = Concatenate()([Conv2DTranspose(128, 4, activation='relu', strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(up4), conv1_1])\n",
        "    up5 = BatchNormalization()(up5)\n",
        "\n",
        "    up6 = Concatenate()([Conv2DTranspose(64, 4, activation='relu', strides=2, padding='same', kernel_initializer='glorot_normal', use_bias=False)(up5), conv1])\n",
        "    up6 = BatchNormalization()(up6)\n",
        "\n",
        "    # Output\n",
        "    output_layer = Conv2DTranspose(output_classes, 4, activation='sigmoid', strides=2, padding='same', kernel_initializer='glorot_normal')(up6)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "AeCmcYOoRWB4"
      },
      "id": "AeCmcYOoRWB4",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "1d60d304",
      "metadata": {
        "id": "1d60d304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "9bdbe03c-ebe4-4d31-aeaa-2ce8bca3e6fc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 12, 12, 512), (None, 11, 11, 512)]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-90aec4b4a2ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-36ab66496643>\u001b[0m in \u001b[0;36munet_model\u001b[0;34m(image_size, output_classes)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mup1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mup2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mup2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mup2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/merging/concatenate.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 )\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 12, 12, 512), (None, 11, 11, 512)]"
          ]
        }
      ],
      "source": [
        "model = unet_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OC-bQoKrH5zG"
      },
      "id": "OC-bQoKrH5zG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa4ffd6e",
      "metadata": {
        "id": "fa4ffd6e"
      },
      "outputs": [],
      "source": [
        "#Компилируем модель\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8199de0",
      "metadata": {
        "id": "a8199de0"
      },
      "outputs": [],
      "source": [
        "# Обучение модели\n",
        "history = model.fit(X_train, Y_train, batch_size=1, epochs=1, validation_data=(X_test, Y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5ff43b",
      "metadata": {
        "id": "4d5ff43b"
      },
      "outputs": [],
      "source": [
        "# Визуализация точности обучения\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Точность модели')\n",
        "plt.ylabel('Точность')\n",
        "plt.xlabel('Количество эпох')\n",
        "plt.legend(['Обучение', 'Тест'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb66edf2",
      "metadata": {
        "id": "cb66edf2"
      },
      "source": [
        "### predict для двух тестовых картинок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e34c320",
      "metadata": {
        "id": "0e34c320"
      },
      "outputs": [],
      "source": [
        "# Прогнозирование для тестовых изображений\n",
        "out = model.predict(X_test[:2], batch_size=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "320b1d94",
      "metadata": {
        "id": "320b1d94"
      },
      "outputs": [],
      "source": [
        "# Визуализация результатов сегментации для тестовых изображений\n",
        "for i in range(2):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.imshow(convert_to_color(np.argmax(Y_test[i], axis=-1)))\n",
        "plt.suptitle('Тестовая сегментация', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Визуализация предсказаний модели\n",
        "for i in range(2):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00b168ac",
      "metadata": {
        "id": "00b168ac"
      },
      "source": [
        "Точность модели 0.8628 при 100 эпохах обучения.  \n",
        "Полученный результат сегментации очень похож на тестовый."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd44db2b",
      "metadata": {
        "id": "cd44db2b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}