{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2AZEFjnEzvvjPlIP2xu/+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annvorosh/GB/blob/NLP/NLP_L05_Pos_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тема «POS-tagger и NER»\n",
        "\n",
        "## Задание 1.\n",
        "- Написать теггер на данных с русским языком\n",
        "- проверить UnigramTagger, BigramTagger, TrigramTagger и их комбинации\n",
        "- написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
        "- сравнить все реализованные методы, сделать выводы  \n",
        "\n",
        "\n",
        "## Задание 2.\n",
        "- Проверить, насколько хорошо работает NER\n",
        "- Данные брать из Index of /pub/named_entities\n",
        "- проверить NER из nltk/spacy/deeppavlov.\n",
        "- написать свой NER, попробовать разные подходы.\n",
        "- передаём в сетку токен и его соседей.\n",
        "- передаём в сетку только токен.\n",
        "- свой вариант.\n",
        "- сравнить свои реализованные подходы на качество — вывести precision/recall/f1_score."
      ],
      "metadata": {
        "id": "AQaZERaPo4rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install corus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57pj5DjMeRtj",
        "outputId": "4a77be28-2232-46e1-8545-74491312ea84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: corus in /usr/local/lib/python3.10/dist-packages (0.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3CSSTC2dqJ-",
        "outputId": "fa954f71-24ab-4bba-f174-a21e86b59414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-28 12:29:00--  https://github.com/UniversalDependencies/UD_Russian-PUD/raw/master/ru_pud-ud-test.conllu\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-PUD/master/ru_pud-ud-test.conllu [following]\n",
            "--2023-07-28 12:29:00--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-PUD/master/ru_pud-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1867908 (1.8M) [text/plain]\n",
            "Saving to: ‘ru_pud-ud-test.conllu.2’\n",
            "\n",
            "\rru_pud-ud-test.conl   0%[                    ]       0  --.-KB/s               \rru_pud-ud-test.conl 100%[===================>]   1.78M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-07-28 12:29:00 (24.1 MB/s) - ‘ru_pud-ud-test.conllu.2’ saved [1867908/1867908]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/UniversalDependencies/UD_Russian-PUD/raw/master/ru_pud-ud-test.conllu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "1nie-acrd9Qj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from corus import load_ud_pud\n",
        "\n",
        "path = 'ru_pud-ud-test.conllu'\n",
        "records = load_ud_pud(path)\n",
        "# next(records)"
      ],
      "metadata": {
        "id": "SV_bJuDHdtqj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger, RegexpTagger, PerceptronTagger\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n"
      ],
      "metadata": {
        "id": "jWES0SMadxt8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получите предложения с разметкой частей речи\n",
        "sentences = [[(token.text, token.pos) for token in record.tokens] for record in records]\n",
        "\n",
        "# Разделите данные на обучающую и тестовую выборки\n",
        "train_size = int(0.8 * len(sentences))\n",
        "train_sent = sentences[:train_size]\n",
        "test_sent = sentences[train_size:]"
      ],
      "metadata": {
        "id": "C5XPnlBZe3tD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание и обучение теггеров\n",
        "unigram_tagger = UnigramTagger(train_sent)\n",
        "bigram_tagger = BigramTagger(train_sent, backoff=unigram_tagger)\n",
        "trigram_tagger = TrigramTagger(train_sent, backoff=bigram_tagger)\n",
        "\n",
        "# Оценка производительности теггеров на тестовых данных\n",
        "print(\"UnigramTagger accuracy:\", unigram_tagger.evaluate(test_sent))\n",
        "print(\"BigramTagger accuracy:\", bigram_tagger.evaluate(test_sent))\n",
        "print(\"TrigramTagger accuracy:\", trigram_tagger.evaluate(test_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6kFbnlyfbCj",
        "outputId": "de5f3a4d-0754-475f-8597-79bfcbbb960e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnigramTagger accuracy: 0.6213304605440345\n",
            "BigramTagger accuracy: 0.6218691085375707\n",
            "TrigramTagger accuracy: 0.6226770805278751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
        "    for cls in tagger_classes:\n",
        "        backoff = cls(train_sents, backoff=backoff)\n",
        "    return backoff\n",
        "\n",
        "\n",
        "backoff = DefaultTagger('NOUN')\n",
        "tag = backoff_tagger(train_sent,\n",
        "                     [UnigramTagger, TrigramTagger, BigramTagger],\n",
        "                     backoff = backoff)\n",
        "\n",
        "tag.evaluate(test_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtN2Ud6-ffdC",
        "outputId": "5aab1ed6-13f6-4340-e77b-5f85a050e126"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7613789388634528"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Комбинация различных теггеров позволяет использовать их преимущества и улучшает результаты. Если один из теггеров не может определить тег для слова, резервный теггер DefaultTagger использует тег 'NOUN', что является общим предположением.\n",
        "Порядок, в котором теггеры используются как резервные, может повлиять на результаты, и изменение этого порядка может привести к небольшому увеличению точности. В нашем случае порядок [UnigramTagger, TrigramTagger, BigramTagger] показал наилучший результат."
      ],
      "metadata": {
        "id": "WU4dBBY5iUK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perceptron_tagger = PerceptronTagger()\n",
        "perceptron_tagger.train(train_sent)\n",
        "print(\"PerceptronTagger accuracy:\", perceptron_tagger.evaluate(test_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrjNZVuSftxy",
        "outputId": "ecabbf7c-f339-46b8-cc6b-737227379cf8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PerceptronTagger accuracy: 0.9081605171020738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ВЫВОД:\n",
        "PerceptronTagger показывает гораздо более высокую точность в сравнении с другими теггерами, так как он использует статистические методы для обучения на размеченных данных."
      ],
      "metadata": {
        "id": "gU2QUzyNhr3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- PUNCT: знаки пунктуации\n",
        "- AUX: вспомогательные глаголы\n",
        "- NOUN: существительные\n",
        "- VERB: глаголы\n",
        "- SCONJ: подчинительные союзы\n",
        "- PRON: местоимения\n",
        "- ADJ: прилагательные"
      ],
      "metadata": {
        "id": "qKtXN_qqkQLq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w02jAR0ejeZR"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patterns = [\n",
        "    # Глаголы\n",
        "    (r'.*ть$', 'VERB'),            # инфинитивы на -ть\n",
        "    (r'.*ать$', 'VERB'),           # инфинитивы на -ать\n",
        "    (r'.*ить$', 'VERB'),           # инфинитивы на -ить\n",
        "    (r'.*еть$', 'VERB'),           # инфинитивы на -еть\n",
        "    (r'.*аться$', 'VERB'),        # возвратные глаголы на -ся\n",
        "    (r'.*сь$', 'VERB'),           # возвратные глаголы на -сь\n",
        "    (r'.*уся$', 'VERB'),          # возвратные глаголы на -уся\n",
        "    (r'.*и$', 'VERB'),             # глаголы на -и\n",
        "    (r'.*ется$', 'VERB'),          # 3-е лицо ед.ч. наст.вр. глаголов на -ить и -еть\n",
        "    (r'.*ем$', 'VERB'),            # 1-е лицо мн.ч. наст.вр. глаголов на -ить и -еть\n",
        "    (r'.*ает$', 'VERB'),           # 3-е лицо ед.ч. наст.вр. глаголов на -ать\n",
        "    (r'.*ают$', 'VERB'),           # 3-е лицо мн.ч. наст.вр. глаголов на -ать\n",
        "    (r'.*яется$', 'VERB'),         # 3-е лицо ед.ч. наст.вр. возвратных глаголов на -иться и -еться\n",
        "    (r'.*емся$', 'VERB'),          # 1-е лицо мн.ч. наст.вр. возвратных глаголов на -иться и -еться\n",
        "    (r'.*аются$', 'VERB'),         # 3-е лицо мн.ч. наст.вр. возвратных глаголов на -аться\n",
        "    (r'.*ится$', 'VERB'),          # 3-е лицо ед.ч. наст.вр. глаголов на -ить\n",
        "    (r'.*ет$', 'VERB'),            # 3-е лицо ед.ч. наст.вр. глаголов на -еть\n",
        "\n",
        "    # Существительные\n",
        "    (r'.*ия$', 'NOUN'),            # существительные на -ия\n",
        "    (r'.*ость$', 'NOUN'),          # существительные на -ость\n",
        "    (r'.*ие$', 'NOUN'),            # существительные на -ие\n",
        "    (r'.*ки$', 'NOUN'),            # существительные на -ки\n",
        "    (r'.*ы$', 'NOUN'),             # существительные на -ы\n",
        "    (r'.*а$', 'NOUN'),             # существительные на -а\n",
        "    (r'.*я$', 'NOUN'),             # существительные на -я\n",
        "    (r'.*о$', 'NOUN'),             # существительные на -о\n",
        "    (r'.*у$', 'NOUN'),             # существительные на -у\n",
        "    (r'.*е$', 'NOUN'),             # существительные на -е\n",
        "    (r'.*сть$', 'NOUN'),           # существительные на -сть\n",
        "    (r'.*ечка$', 'NOUN'),          # существительные на -ечка\n",
        "    (r'.*ище$', 'NOUN'),           # существительные на -ище\n",
        "\n",
        "    # Прилагательные\n",
        "    (r'.*ый$', 'ADJ'),           # прилагательные на -ый\n",
        "    (r'.*ий$', 'ADJ'),           # прилагательные на -ий\n",
        "    (r'.*ая$', 'ADJ'),           # прилагательные на -ая\n",
        "    (r'.*ое$', 'ADJ'),           # прилагательные на -ое\n",
        "    (r'.*ые$', 'ADJ'),           # прилагательные на -ые\n",
        "    (r'.*ь$', 'ADJ'),            # прилагательные на -ь\n",
        "    (r'.*ого$', 'ADJ'),          # прилагательные на -ого\n",
        "    (r'.*его$', 'ADJ'),          # прилагательные на -его\n",
        "\n",
        "    # Наречия\n",
        "    (r'.*о$', 'ADV'),            # наречия на -о\n",
        "    (r'.*е$', 'ADV'),            # наречия на -е\n",
        "    (r'.*но$', 'ADV'),           # наречия на -но\n",
        "\n",
        "    # Числительные\n",
        "    (r'^-?[0-9]+(\\.[0-9]+)?$', 'NUM'),  # целые и десятичные числа\n",
        "\n",
        "    # Местоимения\n",
        "    (r'.*ый$', 'PRON'),           # личные местоимения в форме 2-го лица ед.ч.\n",
        "    (r'.*ая$', 'PRON'),           # личные местоимения в форме 2-го лица ед.ч.\n",
        "    (r'.*ое$', 'PRON'),           # личные местоимения в форме 2-го лица ед.ч.\n",
        "    (r'.*ые$', 'PRON'),           # личные местоимения в форме 2-го лица ед.ч.\n",
        "    (r'.*ого$', 'PRON'),          # личные местоимения в форме 2-го лица ед.ч.\n",
        "    (r'.*он$', 'PRON'),           # личные местоимения в форме 3-го лица ед.ч.\n",
        "    (r'.*она$', 'PRON'),          # личные местоимения в форме 3-го лица ед.ч.\n",
        "    (r'.*они$', 'PRON'),          # личные местоимения в форме мн.ч.\n",
        "    (r'.*их$', 'PRON'),           # личные местоимения в форме родительного падежа\n",
        "\n",
        "    # Предлоги\n",
        "    (r'.*в$', 'ADP'),             # предлоги на -в\n",
        "    (r'.*на$', 'ADP'),            # предлоги на -на\n",
        "    (r'.*с$', 'ADP'),             # предлоги на -с\n",
        "    (r'.*к$', 'ADP'),             # предлоги на -к\n",
        "    (r'.*по$', 'ADP'),            # предлоги на -по\n",
        "    (r'.*за$', 'ADP'),            # предлоги на -за\n",
        "    (r'.*перед$', 'ADP'),         # предлоги на -перед\n",
        "    (r'.*над$', 'ADP'),           # предлоги на -над\n",
        "    (r'.*под$', 'ADP'),           # предлоги на -под\n",
        "    (r'.*между$', 'ADP'),         # предлоги на -между\n",
        "\n",
        "    # Причастия\n",
        "    (r'.*ущий$', 'ADJ'),         # причастия на -ущий\n",
        "    (r'.*ющая$', 'ADJ'),         # причастия на -ющая\n",
        "    (r'.*ющее$', 'ADJ'),         # причастия на -ющее\n",
        "    (r'.*ющие$', 'ADJ'),         # причастия на -ющие\n",
        "    (r'.*емый$', 'ADJ'),         # причастия на -емый\n",
        "    (r'.*омая$', 'ADJ'),         # причастия на -омая\n",
        "    (r'.*имое$', 'ADJ'),         # причастия на -имое\n",
        "    (r'.*имые$', 'ADJ'),         # причастия на -имые\n",
        "    (r'.*енный$', 'ADJ'),        # причастия на -енный\n",
        "    (r'.*енная$', 'ADJ'),        # причастия на -енная\n",
        "    (r'.*енное$', 'ADJ'),        # причастия на -енное\n",
        "    (r'.*енные$', 'ADJ'),        # причастия на -енные\n",
        "\n",
        "    (r'[,.:;?!]', 'PUNCT'),                        # Знаки пунктуации\n",
        "    (r'\\b(?:он|когда|что|они)\\b', 'PRON'),         # Местоимения\n",
        "    (r'\\b(?:когда)\\b', 'SCONJ'),                   # Подчинительные союзы\n",
        "    (r'\\b(?:—)\\b', 'PUNCT'),                       # Знаки пунктуации\n",
        "    (r'\\b(?:быть)\\b', 'AUX'),                       # Вспомогательные глаголы\n",
        "\n",
        "    # Остальные слова\n",
        "    (r'.*', 'NOUN')                # существительные (по умолчанию)\n",
        "]\n"
      ],
      "metadata": {
        "id": "V796f1GNgaAl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regexp_tagger = RegexpTagger(patterns)\n",
        "print(\"RegexpTagger accuracy:\", regexp_tagger.evaluate(test_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyCO0Q3NjDHz",
        "outputId": "f265b12b-2f4d-454f-acc9-fa4d62dcdaa3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RegexpTagger accuracy: 0.4198761109614867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Коэффициент точности (accuracy) 0.4198 для RegexpTagger означает, что использованные регулярные выражения могут не охватывать все возможные случаи, что приводит к низкой точности."
      ],
      "metadata": {
        "id": "gv5cFKG_nuno"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89nJ8XcbjGcm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ke-ZBzvmTwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2.\n",
        "- Проверить, насколько хорошо работает NER\n",
        "- Данные брать из Index of /pub/named_entities\n",
        "- проверить NER из nltk/spacy/deeppavlov.\n",
        "- написать свой NER, попробовать разные подходы.\n",
        "- передаём в сетку токен и его соседей.\n",
        "- передаём в сетку только токен.\n",
        "- свой вариант.\n",
        "- сравнить свои реализованные подходы на качество — вывести precision/recall/f1_score."
      ],
      "metadata": {
        "id": "S1XIKfOirief"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/dice-group/FOX/raw/master/input/Wikiner/aij-wikiner-ru-wp3.bz2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-zdB6n4rjIH",
        "outputId": "5c5ddd88-5b7e-42d5-848d-00d0eceb5eb1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-28 13:33:55--  https://github.com/dice-group/FOX/raw/master/input/Wikiner/aij-wikiner-ru-wp3.bz2\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-ru-wp3.bz2 [following]\n",
            "--2023-07-28 13:33:55--  https://raw.githubusercontent.com/dice-group/FOX/master/input/Wikiner/aij-wikiner-ru-wp3.bz2\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7856559 (7.5M) [application/octet-stream]\n",
            "Saving to: ‘aij-wikiner-ru-wp3.bz2’\n",
            "\n",
            "aij-wikiner-ru-wp3. 100%[===================>]   7.49M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-07-28 13:33:56 (69.0 MB/s) - ‘aij-wikiner-ru-wp3.bz2’ saved [7856559/7856559]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from corus import load_wikiner\n",
        "\n",
        "path = 'aij-wikiner-ru-wp3.bz2'\n",
        "records = load_wikiner(path)\n",
        "# next(records)"
      ],
      "metadata": {
        "id": "16fDFsm9s6uI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание списка предложений с размеченными сущностями в формате, используемом в nltk\n",
        "sentences = []\n",
        "for record in records:\n",
        "    tokens = [(token.text, token.pos, token.tag) for token in record.tokens]\n",
        "    sentences.append(tokens)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "train_size = int(0.8 * len(sentences))\n",
        "train_sent = sentences[:train_size]\n",
        "test_sent = sentences[train_size:]\n"
      ],
      "metadata": {
        "id": "UYciEtCGtO-X"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install spacy\n",
        "# !python -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8zkMNHLuqNh",
        "outputId": "61461b4e-3579-4c3e-e636-49a7df943443"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-07-28 13:41:45.394195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting ru-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.5.0/ru_core_news_sm-3.5.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from ru-core-news-sm==3.5.0) (3.5.4)\n",
            "Collecting pymorphy3>=1.0.0 (from ru-core-news-sm==3.5.0)\n",
            "  Downloading pymorphy3-1.2.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m939.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy3>=1.0.0->ru-core-news-sm==3.5.0)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy3>=1.0.0->ru-core-news-sm==3.5.0)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3>=1.0.0->ru-core-news-sm==3.5.0)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.1.3)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=b5e4de070b7035bdb8b2019054a24c0aba23efd8104908f14b65b1b1362f7d56\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy3-dicts-ru, docopt, dawg-python, pymorphy3, ru-core-news-sm\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy3-1.2.0 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-sm-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования spaCy для NER на русском языке\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"ru_core_news_sm\")\n",
        "text = \"Шимон Перес – единственный израильтянин, который занимал как должность Президента страны, так и должность премьер-министра Израиля (дважды).\"\n",
        "doc = nlp(text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV6f5ydmt7Hs",
        "outputId": "c6fe42df-0a81-4200-92bc-b1dc3a01b341"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Шимон Перес PER\n",
            "Израиля LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZEH48QDvydb"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "0FqlP_BP5GLJ"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ua136GF9ByR"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Для разметки NER с помощью NLTK сначала производим токенизацию слов, затем POS тэггинг.\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def url_to_string(url):\n",
        "    res = requests.get(url)\n",
        "    html = res.text\n",
        "    soup = BeautifulSoup(html, 'html5lib')\n",
        "    for script in soup([\"script\", \"style\", 'aside']):\n",
        "        script.extract()\n",
        "    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))\n",
        "\n",
        "document = 'Нетаньяху объявил утром 29 марта, что Израиль, как ожидается, сможет присоединиться к программе безвизового въезда в США в сентябре 2023 года.'\n",
        "\n",
        "nltk.pos_tag(nltk.word_tokenize(document))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCTsWzJ-xZw7",
        "outputId": "6c4f78a9-e822-435a-9a5c-8742a602386a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Нетаньяху', 'NOUN'),\n",
              " ('объявил', 'VERB'),\n",
              " ('утром', 'NOUN'),\n",
              " ('29', 'CD'),\n",
              " ('марта', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('что', 'SCONJ'),\n",
              " ('Израиль', 'PROPN'),\n",
              " (',', 'PUNCT'),\n",
              " ('как', 'SCONJ'),\n",
              " ('ожидается', 'VERB'),\n",
              " (',', 'PUNCT'),\n",
              " ('сможет', 'VERB'),\n",
              " ('присоединиться', 'VERB'),\n",
              " ('к', 'ADP'),\n",
              " ('программе', 'NOUN'),\n",
              " ('безвизового', 'ADJ'),\n",
              " ('въезда', 'NOUN'),\n",
              " ('в', 'ADP'),\n",
              " ('США', 'PROPN'),\n",
              " ('в', 'ADP'),\n",
              " ('сентябре', 'NOUN'),\n",
              " ('2023', 'ADJ'),\n",
              " ('года', 'NOUN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "it25lB9s4FuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Свой NER"
      ],
      "metadata": {
        "id": "KXLkEg1T-neE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def rule_based_ner(text):\n",
        "    # Define regular expressions for different entity types\n",
        "    date_pattern = (\n",
        "        r'\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b' +\n",
        "        r'|' + r'\\b\\d{1,2}-\\d{1,2}-\\d{2,4}\\b' +\n",
        "        r'|' + r'\\b\\d{1,2}\\.\\d{1,2}\\.\\d{2,4}\\b' +\n",
        "        r'|' + r'\\b\\d{4}-\\d{1,2}-\\d{1,2}\\b' +\n",
        "        r'|' + r'\\b\\d{1,2}/\\d{1,2}\\b' +\n",
        "        r'|' + r'\\b\\d{1,2}-\\d{1,2}\\b' +\n",
        "        r'|' + r'\\b\\d{1,2}\\.\\d{1,2}\\b' +\n",
        "        r'|' + r'\\b\\d{1,2}\\s(?:января|февраля|марта|апреля|мая|июня|июля|августа|сентября|октября|ноября|декабря)(?:\\s\\d{2,4})?\\b' +\n",
        "        r'|' + r'\\b\\d{1,2}\\s(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sept|Oct|Nov|Dec)\\s\\d{2,4}\\b'\n",
        "    )\n",
        "\n",
        "    # Find all matches for each pattern\n",
        "    date_entities = re.findall(date_pattern, text)\n",
        "\n",
        "    # Create a dictionary to store the entities and their types\n",
        "    entities = {}\n",
        "    entities['DATE'] = date_entities\n",
        "\n",
        "    return entities\n",
        "\n",
        "\n",
        "\n",
        "text = \"28 Sept 2016 — Рано утром 28 сентября на 94-м году жизни в медицинском центре 'Шиба' (Тель а-Шомер) скончался бывший президент Израиля ШИмон Перес.\"\n",
        "entities = rule_based_ner(text)\n",
        "print(entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-KeJChTvqai",
        "outputId": "2f346133-43da-45cb-8964-93cea16024b5"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'DATE': ['28 Sept 2016', '28 сентября']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZlP07WB-CZKR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}